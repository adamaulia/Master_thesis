{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pandas as pd \n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as fn\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equivalent_type(f):\n",
    "    if f == 'datetime64[ns]': return DateType()\n",
    "    elif f == 'int64': return LongType()\n",
    "    elif f == 'int32': return IntegerType()\n",
    "    elif f == 'float64': return FloatType()\n",
    "    else: return StringType()\n",
    "\n",
    "def define_structure(string, format_type):\n",
    "    try: typo = equivalent_type(format_type)\n",
    "    except: typo = StringType()\n",
    "    return StructField(string, typo)\n",
    "\n",
    "\n",
    "# Given pandas dataframe, it will return a spark's dataframe.\n",
    "def pandas_to_spark(pandas_df,sparkSession):\n",
    "    columns = list(pandas_df.columns)\n",
    "    types = list(pandas_df.dtypes)\n",
    "    struct_list = []\n",
    "    i = 0\n",
    "    for column, typo in zip(columns, types): \n",
    "        struct_list.append(define_structure(column, typo))\n",
    "    p_schema = StructType(struct_list)\n",
    "    return sparkSession.createDataFrame(pandas_df, p_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start spark engine \n",
    "conf = pyspark.SparkConf().setAppName('tes_spark').setMaster('local')\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.178.31:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>tes_spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x19890b85eb8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer information \n",
    "df_cli = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/data/clients.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cli.select(fn.count(\"client_id\"),fn.countDistinct(\"client_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>first_issue_date</th>\n",
       "      <th>first_redeem_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>2017-08-05 15:40:48</td>\n",
       "      <td>2018-01-04 19:30:07</td>\n",
       "      <td>45</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000036f903</td>\n",
       "      <td>2017-04-10 13:54:23</td>\n",
       "      <td>2017-04-23 12:37:56</td>\n",
       "      <td>72</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000048b7a6</td>\n",
       "      <td>2018-12-15 13:33:11</td>\n",
       "      <td>None</td>\n",
       "      <td>68</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id     first_issue_date    first_redeem_date  age gender\n",
       "0  000012768d  2017-08-05 15:40:48  2018-01-04 19:30:07   45      U\n",
       "1  000036f903  2017-04-10 13:54:23  2017-04-23 12:37:56   72      F\n",
       "2  000048b7a6  2018-12-15 13:33:11                 None   68      F"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cli.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer flag \n",
    "df_up_train = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/data/uplift_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>treatment_flg</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000036f903</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00010925a5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id  treatment_flg  target\n",
       "0  000012768d              0       1\n",
       "1  000036f903              1       1\n",
       "2  00010925a5              1       1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_up_train.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_up_train.select(fn.count(\"client_id\"),fn.countDistinct(\"client_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custommer id for testing\n",
    "df_up_test = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/data/uplift_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000048b7a6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000073194a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007c7133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id\n",
       "0  000048b7a6\n",
       "1  000073194a\n",
       "2  00007c7133"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_up_test.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_up_test.select(fn.count(\"client_id\"),fn.countDistinct(\"client_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product information\n",
    "df_pro = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/data/products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+-----+\n",
      "|   level_1|   level_2|   level_3|   level_4|total|\n",
      "+----------+----------+----------+----------+-----+\n",
      "|ec62ce61e3|36bd2cad67|edbe75f28a|95187f1e43|    1|\n",
      "|c3d3a8e8c6|fb84f08028|4603fa9fa5|510cfe0b63|    1|\n",
      "|ec62ce61e3|a75f1bad01|ebfe092e6a|df5475c6f1|    1|\n",
      "|ec62ce61e3|3ef03403a0|9b3d1f6cb1|6eae515849|    1|\n",
      "|c3d3a8e8c6|fb84f08028|4603fa9fa5|009b538c18|    1|\n",
      "|ec62ce61e3|4202626fcb|a328a6cbdb|1d84a42993|    1|\n",
      "|c3d3a8e8c6|428e08386e|b62e37b39d|48254e6a9b|    1|\n",
      "|ec62ce61e3|6b4ae3f25d|a5b820d60d|fa40a7dbd2|    1|\n",
      "|e344ab2e71|b0c4967fce|eac3f82414|877ad83201|    1|\n",
      "|c3d3a8e8c6|de6f3b925a|cf854d5a22|fca87d4254|    1|\n",
      "|c3d3a8e8c6|f2333c90fb|78800e7c84|6041123c2f|    1|\n",
      "|e344ab2e71|703f4b6eb0|0c37077fa0|ed84e1ad23|    1|\n",
      "|ec62ce61e3|e8705574ff|4ea774ea51|1f2d0f578d|    1|\n",
      "|c3d3a8e8c6|ad2b2e17d2|eda7b2976b|690cbc6ce7|    1|\n",
      "|c3d3a8e8c6|034aca0659|b67737054d|8b97a649bb|    1|\n",
      "|e344ab2e71|ed2ad1797c|57f95167c1|48aaaf19eb|    1|\n",
      "|ec62ce61e3|35642addd4|e0b605262d|218311a924|    1|\n",
      "|c3d3a8e8c6|ad2b2e17d2|2268617da5|6b15f9ca1f|    1|\n",
      "|ec62ce61e3|be86806c6b|58f4db5467|3a6a0afa9d|    1|\n",
      "|ec62ce61e3|f980df59e1|d079294e3a|4ac07f2dd7|    1|\n",
      "+----------+----------+----------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pro.groupby('level_1','level_2','level_3','level_4').agg(fn.count('product_id').alias('total')).sort(\"total\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['product_id',\n",
       " 'level_1',\n",
       " 'level_2',\n",
       " 'level_3',\n",
       " 'level_4',\n",
       " 'segment_id',\n",
       " 'brand_id',\n",
       " 'vendor_id',\n",
       " 'netto',\n",
       " 'is_own_trademark',\n",
       " 'is_alcohol']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pro.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|count(DISTINCT product_id)|\n",
      "+--------------------------+\n",
      "|                     43038|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pro.select(fn.countDistinct('product_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro.select(fn.count(\"product_id\"),fn.countDistinct(\"product_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase transactional data \n",
    "df_pur = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/data/purchases.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data inspection null checking etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pur.select(fn.date_format(fn.col('ts'),\"yyyy-MM-dd\").alias('ts').cast(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pur.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days observation\n",
    "df_pur.select(fn.countDistinct(\"date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start and end data observation \n",
    "df_pur.select(fn.max(\"date\"), fn.min(\"date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many unique products and client \n",
    "df_pur.select(fn.count(\"client_id\"),fn.countDistinct(\"client_id\"), fn.countDistinct('product_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pur.select(fn.countDistinct(\"transaction_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pur.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total spending for each customer\n",
    "df_pur_gb = df_pur.groupby('client_id').agg(fn.sum('purchase_sum').alias('purchase_sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pur_gb.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cli.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cli.createTempView('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry0 = \"\"\"\n",
    "select gender_flag, count(1)n  from (\n",
    "    select \n",
    "    case when first_issue_date is null then 1 else 0 end fid_flag,\n",
    "    case when first_redeem_date is null then 1 else 0 end frd_flag,\n",
    "    case when age is null then 1 else 0 end age_flag,\n",
    "    case when gender is null then 1 else 0 end gender_flag\n",
    "    from tmp \n",
    ")x\n",
    "group by 1\n",
    "\"\"\"\n",
    "\n",
    "# qry0 = \"select first_issue_date from tmp limit 10\"\n",
    "df_tmp = spark.sql(qry0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cli.select(fn.count(\"first_issue_date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_up_train.select([fn.count(fn.when(fn.isnan(c) | fn.col(c).isNull(), c)).alias(c) for c in df_up_train.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_up_train.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_up_train_summ = df_up_train.groupby('treatment_flg', 'target').agg(fn.count('client_id').alias('n_client'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_up_train_summ.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrach month from datetime \n",
    "df_pur = df_pur.withColumn(\"date\", fn.to_date(fn.col(\"transaction_datetime\")))\n",
    "df_pur = df_pur.withColumn(\"month\", fn.date_format(fn.col(\"transaction_datetime\"), \"M\"))\n",
    "df_pur = df_pur.withColumn('day',fn.dayofmonth(df_pur.date))\n",
    "# df_pur = df_pur.withColumn(\"month\", fn.date_format(fn.col(\"transaction_datetime\"), \"M\")) # day of year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- transaction_datetime: string (nullable = true)\n",
      " |-- regular_points_received: double (nullable = true)\n",
      " |-- express_points_received: double (nullable = true)\n",
      " |-- regular_points_spent: double (nullable = true)\n",
      " |-- express_points_spent: double (nullable = true)\n",
      " |-- purchase_sum: double (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_quantity: double (nullable = true)\n",
      " |-- trn_sum_from_iss: double (nullable = true)\n",
      " |-- trn_sum_from_red: double (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pur.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regular and express points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect unique point per transaction \n",
    "df_trans_agg = df_pur.select('client_id','transaction_id','regular_points_received','express_points_received','regular_points_spent','express_points_spent','purchase_sum','month')\\\n",
    "            .groupby('client_id','transaction_id','month')\\\n",
    "            .agg(fn.count('transaction_id').alias('n_trans'),fn.avg('regular_points_received').alias('s_reg_pts_rec'),fn.avg('express_points_received').alias('s_exp_pts_rec')\n",
    "                ,fn.avg('regular_points_spent').alias('s_reg_pts_sp'),fn.avg('express_points_spent').alias('s_exp_pts_sp'), fn.avg('purchase_sum').alias('s_purchase_sum')\n",
    "                )\n",
    "\n",
    "df_trans_agg = df_trans_agg.groupby('client_id','month').agg(fn.sum('s_reg_pts_rec').alias('s_reg_pts_rec'),fn.sum('s_exp_pts_rec').alias('s_exp_pts_rec'),\n",
    "                                                             fn.sum('s_reg_pts_sp').alias('s_reg_pts_sp'),fn.sum('s_exp_pts_sp').alias('s_exp_pts_sp'),\n",
    "                                                             fn.sum('s_purchase_sum').alias('s_purchase_sum'), fn.countDistinct(fn.col('transaction_id')).alias('n_trans'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total regular point received\n",
    "\n",
    "# pivot month\n",
    "df_reg_pts_rec= df_trans_agg.groupBy(\"client_id\").pivot(\"month\").sum(\"s_reg_pts_rec\")\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_reg_pts_rec.columns)):\n",
    "    df_reg_pts_rec = df_reg_pts_rec.withColumnRenamed(df_reg_pts_rec.columns[i], \"m_{}\".format(df_reg_pts_rec.columns[i]))\n",
    "    \n",
    "    \n",
    "df_reg_pts_rec.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/pur_reg_pts_pur.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total express point received\n",
    "\n",
    "# pivot month\n",
    "df_exp_pts_rec= df_trans_agg.groupBy(\"client_id\").pivot(\"month\").sum(\"s_exp_pts_rec\")\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_exp_pts_rec.columns)):\n",
    "    df_exp_pts_rec = df_exp_pts_rec.withColumnRenamed(df_reg_pts_rec.columns[i], \"m_{}\".format(df_reg_pts_rec.columns[i]))\n",
    "    \n",
    "    \n",
    "df_exp_pts_rec.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/pur_exp_pts_pur.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total regular purchased\n",
    "\n",
    "# pivot month\n",
    "df_pur_sum = df_trans_agg.groupBy(\"client_id\").pivot(\"month\").sum(\"s_purchase_sum\")\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_pur_sum.columns)):\n",
    "    df_pur_sum = df_pur_sum.withColumnRenamed(df_pur_sum.columns[i], \"m_{}_ps\".format(df_pur_sum.columns[i]))\n",
    "    \n",
    "    \n",
    "df_pur_sum.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/pur_sum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total regular point spend\n",
    "\n",
    "# pivot month\n",
    "df_reg_pts_spt = df_trans_agg.groupBy(\"client_id\").pivot(\"month\").sum(\"s_reg_pts_sp\")\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_reg_pts_spt.columns)):\n",
    "    df_reg_pts_spt = df_reg_pts_spt.withColumnRenamed(df_reg_pts_spt.columns[i], \"m_{}_ps\".format(df_reg_pts_spt.columns[i]))\n",
    "    \n",
    "    \n",
    "df_reg_pts_spt.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/pur_reg_pts_spt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total express point spend\n",
    "\n",
    "# pivot month\n",
    "df_exp_pts_spt = df_trans_agg.groupBy(\"client_id\").pivot(\"month\").sum(\"s_exp_pts_sp\")\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_exp_pts_spt.columns)):\n",
    "    df_exp_pts_spt = df_exp_pts_spt.withColumnRenamed(df_exp_pts_spt.columns[i], \"m_{}_eps\".format(df_exp_pts_spt.columns[i]))\n",
    "    \n",
    "    \n",
    "df_exp_pts_spt.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/pur_exp_pts_spt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08d1b7df10</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6badd3c893</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3375fc142e</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id     1   11    12     2     3\n",
       "0  08d1b7df10   3.9  NaN   6.9   7.0   4.8\n",
       "1  6badd3c893   0.2  0.7   1.7   8.4   0.2\n",
       "2  3375fc142e  16.5  1.9  23.3  15.2  19.6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg_pts_rec.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product popularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top product transactions each months \n",
    "df_top_product =df_pur.select('client_id','product_id','purchase_sum','month').groupby('client_id','month','product_id')\\\n",
    "                .agg(fn.count('product_id').alias('n_product'),fn.sum('purchase_sum').alias('s_purchase'))\n",
    "\n",
    "# adding row number on purchase and quantity \n",
    "df_top_product = df_top_product.withColumn(\"rank_pur\", fn.row_number().over(Window.partitionBy(\"client_id\",'month').orderBy(fn.col(\"s_purchase\").desc())))\n",
    "df_top_product = df_top_product.withColumn(\"rank_qty\", fn.row_number().over(Window.partitionBy(\"client_id\",'month').orderBy(fn.col(\"n_product\").desc())))\n",
    "\n",
    "# filter top product by purchase\n",
    "df_top_product_purchase = df_top_product.filter(df_top_product.rank_pur == 1)\n",
    "\n",
    "# filter top product by quantity\n",
    "df_top_product_qty = df_top_product.filter(df_top_product.rank_qty == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot product by purchse \n",
    "df_top_product_purchase_gb = df_top_product_purchase.groupby(\"client_id\").pivot(\"month\").agg(fn.first(fn.col('product_id')))\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_top_product_purchase_gb.columns)):\n",
    "    df_top_product_purchase_gb = df_top_product_purchase_gb.withColumnRenamed(df_top_product_purchase_gb.columns[i], \"m_{}_prd_pur\".format(df_top_product_purchase_gb.columns[i]))\n",
    "    \n",
    "df_top_product_purchase_gb.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/pur_prd_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pivot product by qty \n",
    "df_top_product_qty = df_top_product_qty.groupby(\"client_id\").pivot(\"month\").agg(fn.first(fn.col('product_id')))\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_top_product_qty.columns)):\n",
    "    df_top_product_qty = df_top_product_qty.withColumnRenamed(df_top_product_qty.columns[i], \"m_{}_prd_qty\".format(df_top_product_qty.columns[i]))\n",
    "\n",
    "df_top_product_qty.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/pur_prd_qty_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot product by sum purchse \n",
    "df_top_product_purchase_sum = df_top_product_purchase.groupby(\"client_id\").pivot(\"month\").sum('s_purchase')\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_top_product_purchase_sum.columns)):\n",
    "    df_top_product_purchase_sum = df_top_product_purchase_sum.withColumnRenamed(df_top_product_purchase_sum.columns[i], \"m_{}_prd_pur_sum\".format(df_top_product_purchase_sum.columns[i]))\n",
    "\n",
    "df_top_product_purchase_sum.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/pur_prd_sum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot product by total quantity value\n",
    "df_top_product_qty2 = df_top_product_qty.groupby(\"client_id\").pivot(\"month\").sum('n_product')\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_top_product_qty2.columns)):\n",
    "    df_top_product_qty2 = df_top_product_qty2.withColumnRenamed(df_top_product_qty2.columns[i], \"m_{}_prd_pur_qty\".format(df_top_product_qty2.columns[i]))\n",
    "\n",
    "df_top_product_qty2.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/pur_prd_qty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001ecff0a8</td>\n",
       "      <td>68931482c8</td>\n",
       "      <td>None</td>\n",
       "      <td>120c2f5f84</td>\n",
       "      <td>f4599ca21a</td>\n",
       "      <td>4009f09b04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006391ff01</td>\n",
       "      <td>4009f09b04</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4009f09b04</td>\n",
       "      <td>4009f09b04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0068dd084d</td>\n",
       "      <td>075b06cce4</td>\n",
       "      <td>4009f09b04</td>\n",
       "      <td>4009f09b04</td>\n",
       "      <td>a396cc6b08</td>\n",
       "      <td>3ad8062e82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id           1          11          12           2           3\n",
       "0  001ecff0a8  68931482c8        None  120c2f5f84  f4599ca21a  4009f09b04\n",
       "1  006391ff01  4009f09b04        None        None  4009f09b04  4009f09b04\n",
       "2  0068dd084d  075b06cce4  4009f09b04  4009f09b04  a396cc6b08  3ad8062e82"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+---------+----------+--------+--------+\n",
      "| client_id|month|product_id|n_product|s_purchase|rank_pur|rank_qty|\n",
      "+----------+-----+----------+---------+----------+--------+--------+\n",
      "|0004d028a5|   12|89c0fb09aa|        1|    349.79|       1|       1|\n",
      "|0004d028a5|    3|c2749ad87a|        2|    760.96|       1|       1|\n",
      "|0004d028a5|    2|f4599ca21a|        2|   1647.75|       1|       1|\n",
      "|0004d028a5|    1|bc68469f16|        2|     498.0|       1|       1|\n",
      "+----------+-----+----------+---------+----------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_top_product_purchase.filter(df_top_product.client_id == '0004d028a5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+---------+----------+--------+--------+\n",
      "| client_id|month|product_id|n_product|s_purchase|rank_pur|rank_qty|\n",
      "+----------+-----+----------+---------+----------+--------+--------+\n",
      "|0004d028a5|   12|5186e12ff4|        1|     191.0|       1|       1|\n",
      "|0004d028a5|   12|e1387ef699|        1|     191.0|       2|       2|\n",
      "|0004d028a5|   12|89c0fb09aa|        1|    349.79|       3|       3|\n",
      "|0004d028a5|   12|aa9230de5b|        1|    349.79|       4|       4|\n",
      "|0004d028a5|   12|4a29330c8d|        1|    349.79|       5|       5|\n",
      "|0004d028a5|    3|83c0f480db|        1|    265.96|       1|       1|\n",
      "|0004d028a5|    3|f0a594c841|        1|    265.96|       2|       2|\n",
      "|0004d028a5|    3|3f76e5bebd|        1|    265.96|       3|       3|\n",
      "|0004d028a5|    3|0bff7a124a|        1|    398.26|       4|       4|\n",
      "|0004d028a5|    3|f1b1bb97f2|        1|    398.26|       5|       5|\n",
      "|0004d028a5|    3|6372e8152f|        1|    398.26|       6|       6|\n",
      "|0004d028a5|    3|c8ce1d0d31|        1|    398.26|       7|       7|\n",
      "|0004d028a5|    3|4c967be90a|        1|    398.26|       8|       8|\n",
      "|0004d028a5|    3|84ed1d643c|        1|     495.0|       9|       9|\n",
      "|0004d028a5|    3|ae182c4ef7|        1|     495.0|      10|      10|\n",
      "|0004d028a5|    3|b1aa87d337|        1|     601.0|      11|      11|\n",
      "|0004d028a5|    3|f4fdcd6c58|        1|     601.0|      12|      12|\n",
      "|0004d028a5|    3|2a0fe3dbf2|        1|     601.0|      13|      13|\n",
      "|0004d028a5|    3|343e841aaa|        1|     601.0|      14|      14|\n",
      "|0004d028a5|    3|70eeafadd2|        1|     601.0|      15|      15|\n",
      "+----------+-----+----------+---------+----------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_top_product.filter(df_top_product.client_id == '0004d028a5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>month</th>\n",
       "      <th>product_id</th>\n",
       "      <th>n_product</th>\n",
       "      <th>s_purchase</th>\n",
       "      <th>rank_pur</th>\n",
       "      <th>rank_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004d028a5</td>\n",
       "      <td>12</td>\n",
       "      <td>5186e12ff4</td>\n",
       "      <td>1</td>\n",
       "      <td>191.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004d028a5</td>\n",
       "      <td>12</td>\n",
       "      <td>e1387ef699</td>\n",
       "      <td>1</td>\n",
       "      <td>191.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004d028a5</td>\n",
       "      <td>12</td>\n",
       "      <td>89c0fb09aa</td>\n",
       "      <td>1</td>\n",
       "      <td>349.79</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id month  product_id  n_product  s_purchase  rank_pur  rank_qty\n",
       "0  0004d028a5    12  5186e12ff4          1      191.00         1         1\n",
       "1  0004d028a5    12  e1387ef699          1      191.00         2         2\n",
       "2  0004d028a5    12  89c0fb09aa          1      349.79         3         3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_product.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- n_product: long (nullable = false)\n",
      " |-- s_purchase: double (nullable = true)\n",
      " |-- rank_pur: integer (nullable = true)\n",
      " |-- rank_qty: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_top_product.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# store popularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- transaction_datetime: string (nullable = true)\n",
      " |-- regular_points_received: double (nullable = true)\n",
      " |-- express_points_received: double (nullable = true)\n",
      " |-- regular_points_spent: double (nullable = true)\n",
      " |-- express_points_spent: double (nullable = true)\n",
      " |-- purchase_sum: double (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_quantity: double (nullable = true)\n",
      " |-- trn_sum_from_iss: double (nullable = true)\n",
      " |-- trn_sum_from_red: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pur.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracsation summary \n",
    "\n",
    "df_store_gb = df_pur.select('client_id','transaction_id','month','store_id','purchase_sum','product_id').groupby('client_id','month','transaction_id','store_id')\\\n",
    "                    .agg(fn.avg('purchase_sum').alias('s_purchase_sum'), fn.countDistinct('product_id').alias('n_prod_id'))\n",
    "\n",
    "# \n",
    "df_store_gb = df_store_gb.select('client_id','month','transaction_id','store_id','s_purchase_sum','n_prod_id').groupby('client_id','month','store_id')\\\n",
    "              .agg(fn.sum('s_purchase_sum').alias('s_purchase_sum'), fn.avg('n_prod_id').alias('avg_n_prod_id'))                  \n",
    "\n",
    "# unique product per store \n",
    "df_store_gb2 = df_pur.select('client_id','store_id','product_id').groupby('client_id','store_id').agg(fn.countDistinct('product_id').alias('n_product'))\n",
    "df_store_gb2 = df_store_gb2.withColumnRenamed('client_id','client_id2').withColumnRenamed('store_id','store_id2')\n",
    "\n",
    "# join with with unique product for each store \n",
    "df_store_gb = df_store_gb.join(df_store_gb2, (df_store_gb.client_id == df_store_gb2.client_id2) & (df_store_gb.store_id == df_store_gb2.store_id2) , 'inner')\n",
    "\n",
    "df_store_gb = df_store_gb.drop('client_id2','store_id2')\n",
    "\n",
    "# put ranking \n",
    "df_store_gb_rank = df_store_gb.withColumn(\"rank_s_purchase\", fn.row_number().over(Window.partitionBy(\"client_id\",'month').orderBy(fn.col(\"s_purchase_sum\").desc())))\n",
    "df_store_gb_rank = df_store_gb_rank.withColumn(\"rank_prod_qty\", fn.row_number().over(Window.partitionBy(\"client_id\",'month').orderBy(fn.col(\"n_product\").desc())))\n",
    "\n",
    "# filter top product by purchase\n",
    "df_store_gb_top_pur = df_store_gb_rank.filter(df_store_gb_rank.rank_s_purchase == 1)\n",
    "\n",
    "# filter top product by quantity\n",
    "df_store_gb_top_qty = df_store_gb_rank.filter(df_store_gb_rank.rank_prod_qty == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot product by store top purchase  (store) \n",
    "df_store_gb_top_pur_pvt = df_store_gb_top_pur.groupby(\"client_id\").pivot(\"month\").agg(fn.first(fn.col('store_id')))\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_store_gb_top_pur_pvt.columns)):\n",
    "    df_store_gb_top_pur_pvt = df_store_gb_top_pur_pvt.withColumnRenamed(df_store_gb_top_pur_pvt.columns[i], \"m_{}_str_top_pur\".format(df_store_gb_top_pur_pvt.columns[i]))\n",
    "    \n",
    "df_store_gb_top_pur_pvt.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/str_top_pur.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot product by store top purchase  (store) \n",
    "df_store_gb_top_qty_pvt = df_store_gb_top_qty.groupby(\"client_id\").pivot(\"month\").agg(fn.first(fn.col('store_id')))\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_store_gb_top_qty_pvt.columns)):\n",
    "    df_store_gb_top_qty_pvt = df_store_gb_top_qty_pvt.withColumnRenamed(df_store_gb_top_qty_pvt.columns[i], \"m_{}_str_top_qty\".format(df_store_gb_top_qty_pvt.columns[i]))\n",
    "    \n",
    "df_store_gb_top_qty_pvt.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/str_top_qty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot product by store top purchase  (store purchase value ) \n",
    "df_store_gb_top_pur_val_pvt = df_store_gb_top_pur.groupby(\"client_id\").pivot(\"month\").sum('s_purchase_sum')\n",
    "\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_store_gb_top_pur_val_pvt.columns)):\n",
    "    df_store_gb_top_pur_val_pvt = df_store_gb_top_pur_val_pvt.withColumnRenamed(df_store_gb_top_pur_val_pvt.columns[i], \"m_{}_str_top_pur_val\".format(df_store_gb_top_pur_val_pvt.columns[i]))\n",
    "    \n",
    "df_store_gb_top_pur_val_pvt.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/str_top_pur_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot product by store top purchase  (store purchase value ) \n",
    "df_store_gb_top_qty_val_pvt = df_store_gb_top_qty.groupby(\"client_id\").pivot(\"month\").sum('n_product')\n",
    "\n",
    "#rename columns \n",
    "for i in range(1,len(df_store_gb_top_qty_val_pvt.columns)):\n",
    "    df_store_gb_top_qty_val_pvt = df_store_gb_top_qty_val_pvt.withColumnRenamed(df_store_gb_top_qty_val_pvt.columns[i], \"m_{}_str_top_qty_val\".format(df_store_gb_top_qty_val_pvt.columns[i]))\n",
    "    \n",
    "df_store_gb_top_qty_val_pvt.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/str_top_qty_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- s_purchase_sum: double (nullable = true)\n",
      " |-- avg_n_prod_id: double (nullable = true)\n",
      " |-- n_product: long (nullable = false)\n",
      " |-- rank_s_purchase: integer (nullable = true)\n",
      " |-- rank_prod_qty: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_store_gb_top_pur.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2729515"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_gb.count() # 2729515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>month</th>\n",
       "      <th>store_id</th>\n",
       "      <th>s_purchase_sum</th>\n",
       "      <th>avg_n_prod_id</th>\n",
       "      <th>n_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000aef1e0b</td>\n",
       "      <td>12</td>\n",
       "      <td>7bfd87d161</td>\n",
       "      <td>565.67</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000aef1e0b</td>\n",
       "      <td>2</td>\n",
       "      <td>7bfd87d161</td>\n",
       "      <td>569.00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000b0559be</td>\n",
       "      <td>11</td>\n",
       "      <td>7dc4e574be</td>\n",
       "      <td>269.97</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000b0559be</td>\n",
       "      <td>12</td>\n",
       "      <td>7dc4e574be</td>\n",
       "      <td>5837.94</td>\n",
       "      <td>4.888889</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000b0559be</td>\n",
       "      <td>2</td>\n",
       "      <td>7dc4e574be</td>\n",
       "      <td>1440.22</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000b0559be</td>\n",
       "      <td>1</td>\n",
       "      <td>7dc4e574be</td>\n",
       "      <td>235.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001d004e5e</td>\n",
       "      <td>12</td>\n",
       "      <td>18e9a4401d</td>\n",
       "      <td>25.70</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>001dac232d</td>\n",
       "      <td>12</td>\n",
       "      <td>8d3d83fcc1</td>\n",
       "      <td>924.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003cb63a18</td>\n",
       "      <td>3</td>\n",
       "      <td>72c9bdc485</td>\n",
       "      <td>1474.00</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>003cb63a18</td>\n",
       "      <td>11</td>\n",
       "      <td>72c9bdc485</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id month    store_id  s_purchase_sum  avg_n_prod_id  n_product\n",
       "0  000aef1e0b    12  7bfd87d161          565.67      10.000000         21\n",
       "1  000aef1e0b     2  7bfd87d161          569.00      12.000000         21\n",
       "2  000b0559be    11  7dc4e574be          269.97       1.000000         39\n",
       "3  000b0559be    12  7dc4e574be         5837.94       4.888889         39\n",
       "4  000b0559be     2  7dc4e574be         1440.22       4.000000         39\n",
       "5  000b0559be     1  7dc4e574be          235.00       1.000000         39\n",
       "6  001d004e5e    12  18e9a4401d           25.70       1.000000          1\n",
       "7  001dac232d    12  8d3d83fcc1          924.00       4.000000          4\n",
       "8  003cb63a18     3  72c9bdc485         1474.00       7.750000         92\n",
       "9  003cb63a18    11  72c9bdc485         1020.00       8.333333         92"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_gb.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join all features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular points received \n",
    "df_rpr = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/pur_reg_pts_rec.csv\")\n",
    "\n",
    "# express points received \n",
    "df_epr = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/pur_exp_pts_pur.csv\")\n",
    "\n",
    "# purchase sum \n",
    "df_ps = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/pur_sum.csv\")\n",
    "\n",
    "# regular point spent  \n",
    "df_rps = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/pur_reg_pts_spt.csv/\")\n",
    "\n",
    "# express point spent  \n",
    "df_eps = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/pur_exp_pts_spt.csv\")\n",
    "\n",
    "# top product spent by quantity \n",
    "df_prd_qty = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/pur_prd_qty.csv\")\n",
    "\n",
    "# top product spent by quantity \n",
    "df_prd_qty_val = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/pur_prd_qty_val.csv\")\n",
    "\n",
    "# top product spent by sum purchase\n",
    "df_prd_pur = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/pur_prd_sum.csv\")\n",
    "\n",
    "# top product spent by sum purchase\n",
    "df_prd_pur_val = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/pur_prd_sum_val.csv\")\n",
    "\n",
    "#  top store by quantity  \n",
    "df_str_top_pur = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/str_top_pur.csv\")\n",
    "\n",
    "# top store spent store\n",
    "df_str_top_pur_val = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/str_top_pur_val.csv\")\n",
    "\n",
    "#  top store by quantity  \n",
    "df_str_top_qty = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/str_top_qty.csv\")\n",
    "\n",
    "#  top store by quantity  \n",
    "df_str_top_qty_val = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/str_top_qty_val.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>m_1_str_top_pur_val</th>\n",
       "      <th>m_11_str_top_pur_val</th>\n",
       "      <th>m_12_str_top_pur_val</th>\n",
       "      <th>m_2_str_top_pur_val</th>\n",
       "      <th>m_3_str_top_pur_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02c44238cb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>551.00</td>\n",
       "      <td>1749.00</td>\n",
       "      <td>1484.00</td>\n",
       "      <td>2956.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0690e629e9</td>\n",
       "      <td>3413.43</td>\n",
       "      <td>3833.45</td>\n",
       "      <td>2778.86</td>\n",
       "      <td>2580.00</td>\n",
       "      <td>2634.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0799c8ec86</td>\n",
       "      <td>562.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209.00</td>\n",
       "      <td>340.53</td>\n",
       "      <td>91.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id  m_1_str_top_pur_val  m_11_str_top_pur_val  \\\n",
       "0  02c44238cb                  NaN                551.00   \n",
       "1  0690e629e9              3413.43               3833.45   \n",
       "2  0799c8ec86               562.27                   NaN   \n",
       "\n",
       "   m_12_str_top_pur_val  m_2_str_top_pur_val  m_3_str_top_pur_val  \n",
       "0               1749.00              1484.00              2956.00  \n",
       "1               2778.86              2580.00              2634.76  \n",
       "2                209.00               340.53                91.69  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_str_top_pur_val.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rpr = df_rpr.withColumnRenamed('client_id','client_id2')\n",
    "# df_features = df_cli.join(df_rpr, df_cli.client_id == df_rpr.client_id2, 'left' )\n",
    "# df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join customers label and info \n",
    "df_cli = df_cli.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_up_train.join(df_cli,df_up_train.client_id == df_cli.client_id2,'inner')\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with rps \n",
    "df_rpr = df_rpr.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_rpr, df_features.client_id == df_rpr.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with eps \n",
    "df_eps = df_eps.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_eps, df_features.client_id == df_eps.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with ps \n",
    "df_ps = df_ps.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_ps, df_features.client_id == df_ps.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with eps \n",
    "df_rps = df_rps.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_rps, df_features.client_id == df_rps.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with prd_qty \n",
    "df_prd_qty = df_prd_qty.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_prd_qty, df_features.client_id == df_prd_qty.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with prd_purchase\n",
    "df_prd_pur = df_prd_pur.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_prd_pur, df_features.client_id == df_prd_pur.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with prd_qty_value\n",
    "df_prd_qty_val = df_prd_qty_val.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_prd_qty_val, df_features.client_id == df_prd_qty_val.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with prd_pur_value\n",
    "df_prd_pur_val = df_prd_pur_val.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_prd_pur_val, df_features.client_id == df_prd_pur_val.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with top top store quantity \n",
    "df_str_top_qty = df_str_top_qty.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_str_top_qty, df_features.client_id == df_str_top_qty.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with top top store purchase \n",
    "df_str_top_pur = df_str_top_pur.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_str_top_pur, df_features.client_id == df_str_top_pur.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with top top store quantity value \n",
    "df_str_top_qty_val = df_str_top_qty_val.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_str_top_qty_val, df_features.client_id == df_str_top_qty_val.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')\n",
    "\n",
    "# join with top top store quantity value \n",
    "df_str_top_pur_val = df_str_top_pur_val.withColumnRenamed('client_id','client_id2')\n",
    "df_features = df_features.join(df_str_top_pur_val, df_features.client_id == df_str_top_pur_val.client_id2, 'left' )\n",
    "df_features = df_features.drop('client_id2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>treatment_flg</th>\n",
       "      <th>target</th>\n",
       "      <th>first_issue_date</th>\n",
       "      <th>first_redeem_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>m_1_rpr</th>\n",
       "      <th>m_11_rpr</th>\n",
       "      <th>m_12_rpr</th>\n",
       "      <th>...</th>\n",
       "      <th>m_1_str_top_qty_val</th>\n",
       "      <th>m_11_str_top_qty_val</th>\n",
       "      <th>m_12_str_top_qty_val</th>\n",
       "      <th>m_2_str_top_qty_val</th>\n",
       "      <th>m_3_str_top_qty_val</th>\n",
       "      <th>m_1_str_top_pur_val</th>\n",
       "      <th>m_11_str_top_pur_val</th>\n",
       "      <th>m_12_str_top_pur_val</th>\n",
       "      <th>m_2_str_top_pur_val</th>\n",
       "      <th>m_3_str_top_pur_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00f6cab0d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-09-14 15:27:21</td>\n",
       "      <td>2017-12-25 16:27:54</td>\n",
       "      <td>48</td>\n",
       "      <td>U</td>\n",
       "      <td>17.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.5</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>1811.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2844.54</td>\n",
       "      <td>1360.99</td>\n",
       "      <td>1732.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010c5002de</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-24 12:43:19</td>\n",
       "      <td>2018-11-12 21:39:30</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>749.84</td>\n",
       "      <td>307.56</td>\n",
       "      <td>1537.70</td>\n",
       "      <td>764.03</td>\n",
       "      <td>728.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>018253c9e4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-19 18:00:10</td>\n",
       "      <td>2018-11-29 15:13:23</td>\n",
       "      <td>78</td>\n",
       "      <td>U</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "      <td>972.00</td>\n",
       "      <td>309.00</td>\n",
       "      <td>2196.00</td>\n",
       "      <td>813.00</td>\n",
       "      <td>223.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id  treatment_flg  target     first_issue_date  \\\n",
       "0  00f6cab0d9              0       1  2017-09-14 15:27:21   \n",
       "1  010c5002de              1       1  2018-10-24 12:43:19   \n",
       "2  018253c9e4              0       0  2018-01-19 18:00:10   \n",
       "\n",
       "     first_redeem_date  age gender  m_1_rpr  m_11_rpr  m_12_rpr  ...  \\\n",
       "0  2017-12-25 16:27:54   48      U     17.6       NaN      26.5  ...   \n",
       "1  2018-11-12 21:39:30   27      M      3.2       3.0       8.6  ...   \n",
       "2  2018-11-29 15:13:23   78      U     16.4       0.0      28.6  ...   \n",
       "\n",
       "   m_1_str_top_qty_val  m_11_str_top_qty_val  m_12_str_top_qty_val  \\\n",
       "0                   83                   NaN                    83   \n",
       "1                   40                  40.0                    40   \n",
       "2                   39                  39.0                    39   \n",
       "\n",
       "   m_2_str_top_qty_val  m_3_str_top_qty_val  m_1_str_top_pur_val  \\\n",
       "0                   83                   83              1811.24   \n",
       "1                   40                   40               749.84   \n",
       "2                   39                   28               972.00   \n",
       "\n",
       "   m_11_str_top_pur_val  m_12_str_top_pur_val  m_2_str_top_pur_val  \\\n",
       "0                   NaN               2844.54              1360.99   \n",
       "1                307.56               1537.70               764.03   \n",
       "2                309.00               2196.00               813.00   \n",
       "\n",
       "   m_3_str_top_pur_val  \n",
       "0              1732.33  \n",
       "1               728.48  \n",
       "2               223.00  \n",
       "\n",
       "[3 rows x 67 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- treatment_flg: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- first_issue_date: string (nullable = true)\n",
      " |-- first_redeem_date: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- m_1_rpr: double (nullable = true)\n",
      " |-- m_11_rpr: double (nullable = true)\n",
      " |-- m_12_rpr: double (nullable = true)\n",
      " |-- m_2_rpr: double (nullable = true)\n",
      " |-- m_3_rpr: double (nullable = true)\n",
      " |-- m_1_eps: double (nullable = true)\n",
      " |-- m_11_eps: double (nullable = true)\n",
      " |-- m_12_eps: double (nullable = true)\n",
      " |-- m_2_eps: double (nullable = true)\n",
      " |-- m_3_eps: double (nullable = true)\n",
      " |-- m_1_ps: double (nullable = true)\n",
      " |-- m_11_ps: double (nullable = true)\n",
      " |-- m_12_ps: double (nullable = true)\n",
      " |-- m_2_ps: double (nullable = true)\n",
      " |-- m_3_ps: double (nullable = true)\n",
      " |-- m_1_rps: double (nullable = true)\n",
      " |-- m_11_rps: double (nullable = true)\n",
      " |-- m_12_rps: double (nullable = true)\n",
      " |-- m_2_rps: double (nullable = true)\n",
      " |-- m_3_rps: double (nullable = true)\n",
      " |-- m_1_prd_qty_val: string (nullable = true)\n",
      " |-- m_11_prd_qty_val: string (nullable = true)\n",
      " |-- m_12_prd_qty_val: string (nullable = true)\n",
      " |-- m_2_prd_qty_val: string (nullable = true)\n",
      " |-- m_3_prd_qty_val: string (nullable = true)\n",
      " |-- m_1_prd_pur: string (nullable = true)\n",
      " |-- m_11_prd_pur: string (nullable = true)\n",
      " |-- m_12_prd_pur: string (nullable = true)\n",
      " |-- m_2_prd_pur: string (nullable = true)\n",
      " |-- m_3_prd_pur: string (nullable = true)\n",
      " |-- m_1_prd_pur_qty: integer (nullable = true)\n",
      " |-- m_11_prd_pur_qty: integer (nullable = true)\n",
      " |-- m_12_prd_pur_qty: integer (nullable = true)\n",
      " |-- m_2_prd_pur_qty: integer (nullable = true)\n",
      " |-- m_3_prd_pur_qty: integer (nullable = true)\n",
      " |-- m_1_prd_pur_sum: double (nullable = true)\n",
      " |-- m_11_prd_pur_sum: double (nullable = true)\n",
      " |-- m_12_prd_pur_sum: double (nullable = true)\n",
      " |-- m_2_prd_pur_sum: double (nullable = true)\n",
      " |-- m_3_prd_pur_sum: double (nullable = true)\n",
      " |-- m_1_str_top_qty: string (nullable = true)\n",
      " |-- m_11_str_top_qty: string (nullable = true)\n",
      " |-- m_12_str_top_qty: string (nullable = true)\n",
      " |-- m_2_str_top_qty: string (nullable = true)\n",
      " |-- m_3_str_top_qty: string (nullable = true)\n",
      " |-- m_1_str_top_pur: string (nullable = true)\n",
      " |-- m_11_str_top_pur: string (nullable = true)\n",
      " |-- m_12_str_top_pur: string (nullable = true)\n",
      " |-- m_2_str_top_pur: string (nullable = true)\n",
      " |-- m_3_str_top_pur: string (nullable = true)\n",
      " |-- m_1_str_top_qty_val: integer (nullable = true)\n",
      " |-- m_11_str_top_qty_val: integer (nullable = true)\n",
      " |-- m_12_str_top_qty_val: integer (nullable = true)\n",
      " |-- m_2_str_top_qty_val: integer (nullable = true)\n",
      " |-- m_3_str_top_qty_val: integer (nullable = true)\n",
      " |-- m_1_str_top_pur_val: double (nullable = true)\n",
      " |-- m_11_str_top_pur_val: double (nullable = true)\n",
      " |-- m_12_str_top_pur_val: double (nullable = true)\n",
      " |-- m_2_str_top_pur_val: double (nullable = true)\n",
      " |-- m_3_str_top_pur_val: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.repartition(1).write.option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/feature_stg1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------------+\n",
      "|count(client_id)|count(DISTINCT client_id)|\n",
      "+----------------+-------------------------+\n",
      "|          200039|                   200039|\n",
      "+----------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features.select(fn.count(fn.col('client_id')),fn.countDistinct(fn.col('client_id'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"), \\\n",
    "      (\"Orange\",2000,\"USA\"),(\"Orange\",2000,\"USA\"),(\"Banana\",400,\"China\"), \\\n",
    "      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"), \\\n",
    "      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n",
    "\n",
    "columns= [\"Product\",\"Amount\",\"Country\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|Product|Amount|Country|\n",
      "+-------+------+-------+\n",
      "| Banana|  1000|    USA|\n",
      "|Carrots|  1500|    USA|\n",
      "|  Beans|  1600|    USA|\n",
      "+-------+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Canada: long (nullable = true)\n",
      " |-- China: long (nullable = true)\n",
      " |-- Mexico: long (nullable = true)\n",
      " |-- USA: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivotDF = df.groupBy(\"Product\").pivot(\"Country\").sum(\"Amount\")\n",
    "pivotDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Canada</th>\n",
       "      <th>China</th>\n",
       "      <th>Mexico</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banana</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product  Canada  China  Mexico   USA\n",
       "0  Orange     NaN   4000     NaN  4000\n",
       "1   Beans     NaN   1500  2000.0  1600\n",
       "2  Banana  2000.0    400     NaN  1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivotDF.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_agg.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_agg.select(fn.countDistinct(fn.col('month'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_pts_rec.select(fn.count(fn.col('transaction_id')),fn.countDistinct(fn.col('transaction_id'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pur.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
