{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd \n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as fn\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf, datediff, to_date, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equivalent_type(f):\n",
    "    if f == 'datetime64[ns]': return DateType()\n",
    "    elif f == 'int64': return LongType()\n",
    "    elif f == 'int32': return IntegerType()\n",
    "    elif f == 'float64': return FloatType()\n",
    "    else: return StringType()\n",
    "\n",
    "def define_structure(string, format_type):\n",
    "    try: typo = equivalent_type(format_type)\n",
    "    except: typo = StringType()\n",
    "    return StructField(string, typo)\n",
    "\n",
    "\n",
    "# Given pandas dataframe, it will return a spark's dataframe.\n",
    "def pandas_to_spark(pandas_df,sparkSession):\n",
    "    columns = list(pandas_df.columns)\n",
    "    types = list(pandas_df.dtypes)\n",
    "    struct_list = []\n",
    "    i = 0\n",
    "    for column, typo in zip(columns, types): \n",
    "        struct_list.append(define_structure(column, typo))\n",
    "    p_schema = StructType(struct_list)\n",
    "    return sparkSession.createDataFrame(pandas_df, p_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start spark engine \n",
    "conf = pyspark.SparkConf().setAppName('tes_spark').setMaster('local')\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer information \n",
    "df_cli = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/data/clients.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer flag \n",
    "df_up_train = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/data/uplift_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custommer id for testing\n",
    "df_up_test = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/data/uplift_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product information\n",
    "df_pro = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/data/products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase transactional data \n",
    "df_pur = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"../../data/data/purchases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_df = spark \\\n",
    "    .read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .load(\"D:/works/master_tilburg/dss/thesis/data/feature_stg2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>regular_points_received</th>\n",
       "      <th>express_points_spent</th>\n",
       "      <th>purchase_sum</th>\n",
       "      <th>avg_n_prod</th>\n",
       "      <th>avg_n_prod_qty</th>\n",
       "      <th>trn_sum_from_iss</th>\n",
       "      <th>trn_sum_from_red</th>\n",
       "      <th>n_transaction</th>\n",
       "      <th>store_id_pur</th>\n",
       "      <th>s_purchase_sum</th>\n",
       "      <th>store_id_pur_qty</th>\n",
       "      <th>store_n_product</th>\n",
       "      <th>product_pur</th>\n",
       "      <th>s_purchase</th>\n",
       "      <th>product_qty</th>\n",
       "      <th>n_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02429418df</td>\n",
       "      <td>37.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4156.77</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>539.914286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>d09acf8114</td>\n",
       "      <td>1349.00</td>\n",
       "      <td>2fe93e36be</td>\n",
       "      <td>21</td>\n",
       "      <td>4009f09b04</td>\n",
       "      <td>3190.70</td>\n",
       "      <td>4009f09b04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02d6c08e7d</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>747.00</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>30.0</td>\n",
       "      <td>500.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>7763d9b151</td>\n",
       "      <td>721.00</td>\n",
       "      <td>7763d9b151</td>\n",
       "      <td>8</td>\n",
       "      <td>21e8f864ff</td>\n",
       "      <td>506.00</td>\n",
       "      <td>21e8f864ff</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03f35da9a5</td>\n",
       "      <td>30.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5661.85</td>\n",
       "      <td>3.647059</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1455.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>04d336aec5</td>\n",
       "      <td>5661.85</td>\n",
       "      <td>04d336aec5</td>\n",
       "      <td>47</td>\n",
       "      <td>222c727a1d</td>\n",
       "      <td>2090.06</td>\n",
       "      <td>222c727a1d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id  regular_points_received  express_points_spent  purchase_sum  \\\n",
       "0  02429418df                     37.3                   0.0       4156.77   \n",
       "1  02d6c08e7d                      5.9                   0.0        747.00   \n",
       "2  03f35da9a5                     30.2                   0.0       5661.85   \n",
       "\n",
       "   avg_n_prod  avg_n_prod_qty  trn_sum_from_iss  trn_sum_from_red  \\\n",
       "0    8.500000            62.0        539.914286               0.0   \n",
       "1    1.888889            30.0        500.583333               0.0   \n",
       "2    3.647059            87.0       1455.900000               0.0   \n",
       "\n",
       "   n_transaction store_id_pur  s_purchase_sum store_id_pur_qty  \\\n",
       "0              6   d09acf8114         1349.00       2fe93e36be   \n",
       "1              9   7763d9b151          721.00       7763d9b151   \n",
       "2             17   04d336aec5         5661.85       04d336aec5   \n",
       "\n",
       "   store_n_product product_pur  s_purchase product_qty  n_product  \n",
       "0               21  4009f09b04     3190.70  4009f09b04          3  \n",
       "1                8  21e8f864ff      506.00  21e8f864ff          7  \n",
       "2               47  222c727a1d     2090.06  222c727a1d          4  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes_df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 11, 20)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.date(2019, 11, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 11, 20, 12, 37, 56)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime(2019, 11, 20, 12,37,56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing value in first redeem date with max date \n",
    "df_cli = df_cli.withColumn('first_redeem_date2', fn.when(fn.col('first_redeem_date').isNull(), dt.datetime(2019, 11, 20, 1,14,10)).otherwise(fn.col('first_redeem_date')))\n",
    "df_cli = df_cli.drop('first_redeem_date')\n",
    "df_cli = df_cli.withColumnRenamed('first_redeem_date2','first_redeem_date')\n",
    "df_cli = df_cli.withColumn(\"first_redeem_date\", fn.to_date(fn.col(\"first_redeem_date\")))\n",
    "\n",
    "# adding train label \n",
    "df_up_train = df_up_train.withColumnRenamed('client_id','client_id2')\n",
    "df_cli = df_cli.join(df_up_train, df_cli.client_id == df_up_train.client_id2,'inner')\n",
    "df_cli = df_cli.drop('client_id2')\n",
    "\n",
    "# fill na values in purchase \n",
    "df_pur =  df_pur.fillna(value=0,subset=[\"trn_sum_from_red\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>transaction_datetime</th>\n",
       "      <th>regular_points_received</th>\n",
       "      <th>express_points_received</th>\n",
       "      <th>regular_points_spent</th>\n",
       "      <th>express_points_spent</th>\n",
       "      <th>purchase_sum</th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_quantity</th>\n",
       "      <th>trn_sum_from_iss</th>\n",
       "      <th>trn_sum_from_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>9a80204f78</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>da89ebd374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>0a95e1151d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>4055b15e4a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>a685f1916b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>21db5dbe53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>1e208d0b4c</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>15ccaa8685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>45389bb5b0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>cb4c804130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>7c39f1d12c</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>63e2eac70d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>c7cc613e79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>ad865591c6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>7118c66f7f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>c55ed13ebd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>9cdad65286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>17cf3963fb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>6bbace0869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     client_id transaction_id transaction_datetime  regular_points_received  \\\n",
       "0   000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "1   000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "2   000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "3   000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "4   000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "5   000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "6   000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "7   000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "8   000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "9   000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "10  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "11  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "12  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "13  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "14  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "15  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "16  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "17  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "18  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "\n",
       "    express_points_received  regular_points_spent  express_points_spent  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "5                       0.0                   0.0                   0.0   \n",
       "6                       0.0                   0.0                   0.0   \n",
       "7                       0.0                   0.0                   0.0   \n",
       "8                       0.0                   0.0                   0.0   \n",
       "9                       0.0                   0.0                   0.0   \n",
       "10                      0.0                   0.0                   0.0   \n",
       "11                      0.0                   0.0                   0.0   \n",
       "12                      0.0                   0.0                   0.0   \n",
       "13                      0.0                   0.0                   0.0   \n",
       "14                      0.0                   0.0                   0.0   \n",
       "15                      0.0                   0.0                   0.0   \n",
       "16                      0.0                   0.0                   0.0   \n",
       "17                      0.0                   0.0                   0.0   \n",
       "18                      0.0                   0.0                   0.0   \n",
       "\n",
       "    purchase_sum    store_id  product_id  product_quantity  trn_sum_from_iss  \\\n",
       "0         1007.0  54a4a11a29  9a80204f78               2.0              80.0   \n",
       "1         1007.0  54a4a11a29  da89ebd374               1.0              65.0   \n",
       "2         1007.0  54a4a11a29  0a95e1151d               1.0              24.0   \n",
       "3         1007.0  54a4a11a29  4055b15e4a               2.0              50.0   \n",
       "4         1007.0  54a4a11a29  a685f1916b               1.0              22.0   \n",
       "5         1007.0  54a4a11a29  21db5dbe53               1.0              34.0   \n",
       "6         1007.0  54a4a11a29  1e208d0b4c               1.0              24.0   \n",
       "7         1007.0  54a4a11a29  15ccaa8685               1.0              51.0   \n",
       "8         1007.0  54a4a11a29  45389bb5b0               1.0              23.0   \n",
       "9         1007.0  54a4a11a29  cb4c804130               1.0              60.0   \n",
       "10        1007.0  54a4a11a29  7c39f1d12c               1.0              67.0   \n",
       "11        1007.0  54a4a11a29  63e2eac70d               1.0              40.0   \n",
       "12        1007.0  54a4a11a29  c7cc613e79               1.0              90.0   \n",
       "13        1007.0  54a4a11a29  ad865591c6               1.0              49.0   \n",
       "14        1007.0  54a4a11a29  7118c66f7f               1.0              40.0   \n",
       "15        1007.0  54a4a11a29  c55ed13ebd               1.0              80.0   \n",
       "16        1007.0  54a4a11a29  9cdad65286               1.0              58.0   \n",
       "17        1007.0  54a4a11a29  17cf3963fb               1.0              68.0   \n",
       "18        1007.0  54a4a11a29  6bbace0869               1.0              82.0   \n",
       "\n",
       "    trn_sum_from_red  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "5                0.0  \n",
       "6                0.0  \n",
       "7                0.0  \n",
       "8                0.0  \n",
       "9                0.0  \n",
       "10               0.0  \n",
       "11               0.0  \n",
       "12               0.0  \n",
       "13               0.0  \n",
       "14               0.0  \n",
       "15               0.0  \n",
       "16               0.0  \n",
       "17               0.0  \n",
       "18               0.0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pur.filter(df_pur.transaction_id == '7e3e2e3984').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>transaction_datetime</th>\n",
       "      <th>regular_points_received</th>\n",
       "      <th>express_points_received</th>\n",
       "      <th>regular_points_spent</th>\n",
       "      <th>express_points_spent</th>\n",
       "      <th>purchase_sum</th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_quantity</th>\n",
       "      <th>trn_sum_from_iss</th>\n",
       "      <th>trn_sum_from_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>9a80204f78</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>da89ebd374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>0a95e1151d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id transaction_id transaction_datetime  regular_points_received  \\\n",
       "0  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "1  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "2  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "\n",
       "   express_points_received  regular_points_spent  express_points_spent  \\\n",
       "0                      0.0                   0.0                   0.0   \n",
       "1                      0.0                   0.0                   0.0   \n",
       "2                      0.0                   0.0                   0.0   \n",
       "\n",
       "   purchase_sum    store_id  product_id  product_quantity  trn_sum_from_iss  \\\n",
       "0        1007.0  54a4a11a29  9a80204f78               2.0              80.0   \n",
       "1        1007.0  54a4a11a29  da89ebd374               1.0              65.0   \n",
       "2        1007.0  54a4a11a29  0a95e1151d               1.0              24.0   \n",
       "\n",
       "   trn_sum_from_red  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pur.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- first_issue_date: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- first_redeem_date: date (nullable = true)\n",
      " |-- treatment_flg: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cli.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join client and purchase \n",
    "df_cli = df_cli.withColumnRenamed('client_id','client_id2')\n",
    "\n",
    "df_cli_pur = df_cli.join(df_pur,df_cli.client_id2 == df_pur.client_id,'inner')\n",
    "df_cli_pur = df_cli_pur.drop('client_id2')\n",
    "\n",
    "# keep transactiion before redeem date \n",
    "df_cli_pur = df_cli_pur.withColumn(\"transaction_datetime\", fn.to_date(fn.col(\"transaction_datetime\")))\n",
    "df_cli_pur = df_cli_pur.withColumn('trans_redeem_flag',fn.when(fn.col('transaction_datetime') < fn.col('first_redeem_date'),1).otherwise(0)) # 1 keep, 0 remove \n",
    "\n",
    "# add target \n",
    "df_up_train = df_up_train.withColumnRenamed('client_id','client_id2')\n",
    "# df_cli_pur = df_cli_pur.join(df_up_train,df_cli_pur.client_id==df_up_train.client_id2,'inner')\n",
    "# df_cli_pur = df_cli_pur.drop('client_id2')\n",
    "\n",
    "# date difference \n",
    "df_cli_pur = df_cli_pur.withColumn(\"d_iss_rdm\", datediff(fn.col('first_redeem_date'), fn.col('first_issue_date')))\n",
    "df_cli_pur = df_cli_pur.withColumn(\"d_trs_rdm\", datediff(fn.col('first_redeem_date'), fn.col('transaction_datetime')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_issue_date: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- first_redeem_date: date (nullable = true)\n",
      " |-- treatment_flg: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- transaction_datetime: date (nullable = true)\n",
      " |-- regular_points_received: double (nullable = true)\n",
      " |-- express_points_received: double (nullable = true)\n",
      " |-- regular_points_spent: double (nullable = true)\n",
      " |-- express_points_spent: double (nullable = true)\n",
      " |-- purchase_sum: double (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_quantity: double (nullable = true)\n",
      " |-- trn_sum_from_iss: double (nullable = true)\n",
      " |-- trn_sum_from_red: double (nullable = false)\n",
      " |-- trans_redeem_flag: integer (nullable = false)\n",
      " |-- d_iss_rdm: integer (nullable = true)\n",
      " |-- d_trs_rdm: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cli_pur.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points aggregation split by before and after redeem code \n",
    "df_feat1 = df_cli_pur.groupby('client_id','age','gender','treatment_flg','target','trans_redeem_flag').agg(fn.countDistinct('transaction_id').alias('n_trans_rdm'), fn.countDistinct('transaction_datetime').alias('days_redeem'))\n",
    "\n",
    "# pivot\n",
    "df_feat1a = df_feat1.groupBy('client_id').pivot(\"trans_redeem_flag\").sum(\"n_trans_rdm\")\n",
    "df_feat1a = df_feat1a.withColumnRenamed('0','n_trans_atr_rdm').withColumnRenamed('1','n_trans_bfr_rdm')\n",
    "df_feat1b = df_feat1.groupBy('client_id').pivot(\"trans_redeem_flag\").sum(\"days_redeem\")\n",
    "df_feat1b = df_feat1b.withColumnRenamed('0','n_days_bfr_rdm').withColumnRenamed('1','n_days_atr_rdm')\n",
    "\n",
    "# join 1a and 1b \n",
    "df_feat1b = df_feat1b.withColumnRenamed('client_id','client_id2')\n",
    "df_feat1_agg = df_feat1a.join(df_feat1b,df_feat1a.client_id == df_feat1b.client_id2,'left').drop('client_id2')\n",
    "\n",
    "df_feat1_agg.repartition(1).write.mode('overwrite').option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/feat_n_day_trans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular points, express points and avg purchase \n",
    "\n",
    "df_feat2 = df_cli_pur.groupby('client_id','age','gender','treatment_flg','target','trans_redeem_flag','transaction_id').agg(fn.avg('regular_points_received').alias('regular_points_received'), \\\n",
    "                                                                                                             fn.avg('express_points_received').alias('express_points_received'), \\\n",
    "                                                                                                            fn.avg('purchase_sum').alias('purchase_sum')\n",
    "                                                                                                            )\n",
    "\n",
    "df_feat2 = df_feat2.groupby('client_id','age','gender','treatment_flg','target','trans_redeem_flag').agg(fn.sum('regular_points_received').alias('s_reg_pts_rdm'),fn.avg('regular_points_received').alias('avg_reg_pts_rdm'),\\\n",
    "                                                                                         fn.sum('express_points_received').alias('s_exp_pts_rdm'),fn.avg('express_points_received').alias('avg_exp_pts_rdm'),\\\n",
    "                                                                                         fn.sum('purchase_sum').alias('s_purchase'),fn.avg('purchase_sum').alias('avg_purchase'),\\\n",
    "                                                                                          fn.countDistinct('transaction_id').alias('n_trans')\n",
    "                                                                                         )\n",
    "\n",
    "df_feat2a = df_feat2.groupby('client_id').pivot('trans_redeem_flag').agg(fn.sum('s_reg_pts_rdm').alias('s_reg_pts_rdm'))\n",
    "df_feat2b = df_feat2.groupby('client_id').pivot('trans_redeem_flag').agg(fn.sum('avg_reg_pts_rdm').alias('avg_reg_pts_rdm'))\n",
    "\n",
    "df_feat2c = df_feat2.groupby('client_id').pivot('trans_redeem_flag').agg(fn.sum('s_exp_pts_rdm').alias('s_exp_pts_rdm'))\n",
    "df_feat2d = df_feat2.groupby('client_id').pivot('trans_redeem_flag').agg(fn.sum('avg_exp_pts_rdm').alias('avg_exp_pts_rdm'))\n",
    "\n",
    "df_feat2e = df_feat2.groupby('client_id').pivot('trans_redeem_flag').agg(fn.sum('s_purchase').alias('s_purchase'))\n",
    "df_feat2f = df_feat2.groupby('client_id').pivot('trans_redeem_flag').agg(fn.sum('avg_purchase').alias('avg_purchase'))\n",
    "\n",
    "df_feat2g = df_feat2.groupby('client_id').pivot('trans_redeem_flag').agg(fn.sum('n_trans').alias('n_trans'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat2a = df_feat2a.withColumnRenamed('0','s_reg_pts_bfr_rdm').withColumnRenamed('1','s_reg_pts_atr_rdm') \n",
    "df_feat2b = df_feat2b.withColumnRenamed('client_id','client_id2').withColumnRenamed('0','avg_reg_pts_bfr_rdm').withColumnRenamed('1','avg_reg_pts_aft_rdm')\n",
    "df_feat2_agg = df_feat2a.join(df_feat2b, df_feat2a.client_id==df_feat2b.client_id2,'left').drop('client_id2')\n",
    "\n",
    "\n",
    "df_feat2c = df_feat2c.withColumnRenamed('client_id','client_id2').withColumnRenamed('0','s_exp_pts_bfr_rdm').withColumnRenamed('1','s_exp_pts_aft_rdm')\n",
    "df_feat2_agg = df_feat2_agg.join(df_feat2c, df_feat2_agg.client_id == df_feat2c.client_id2,'left').drop('client_id2')\n",
    "\n",
    "df_feat2d = df_feat2d.withColumnRenamed('client_id','client_id2').withColumnRenamed('0','avg_exp_pts_bfr_rdm').withColumnRenamed('1','avg_exp_pts_aft_rdm')\n",
    "df_feat2_agg = df_feat2_agg.join(df_feat2d, df_feat2_agg.client_id == df_feat2d.client_id2,'left').drop('client_id2')\n",
    "\n",
    "df_feat2e = df_feat2e.withColumnRenamed('client_id','client_id2').withColumnRenamed('0','s_pur_bfr_rdm').withColumnRenamed('1','s_pur_aft_rdm')\n",
    "df_feat2_agg = df_feat2_agg.join(df_feat2e, df_feat2_agg.client_id == df_feat2e.client_id2,'left').drop('client_id2')\n",
    "\n",
    "df_feat2f = df_feat2f.withColumnRenamed('client_id','client_id2').withColumnRenamed('0','avg_pur_bfr_rdm').withColumnRenamed('1','avg_pur_aft_rdm')\n",
    "df_feat2_agg = df_feat2_agg.join(df_feat2f, df_feat2_agg.client_id == df_feat2f.client_id2,'left').drop('client_id2')\n",
    "\n",
    "df_feat2g = df_feat2g.withColumnRenamed('client_id','client_id2').withColumnRenamed('0','n_trans_bfr_rdm').withColumnRenamed('1','n_trans_aft_rdm')\n",
    "df_feat2_agg = df_feat2_agg.join(df_feat2g, df_feat2_agg.client_id == df_feat2g.client_id2,'left').drop('client_id2')\n",
    "\n",
    "df_feat2_agg.repartition(1).write.mode('overwrite').option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/feat2_pts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg pur per trans\n",
    "df_feat3_agg =df_cli_pur.select('client_id','product_id','transaction_id','product_quantity','trans_redeem_flag').groupby('client_id','transaction_id','trans_redeem_flag','product_id')\\\n",
    "                .agg(fn.avg('product_quantity').alias('product_quantity'))\n",
    "\n",
    "\n",
    "df_feat3_agg2 = df_feat3_agg.groupby('client_id','product_id').agg(fn.sum('product_quantity').alias('product_quantity'))\n",
    "df_feat3_agg2 = df_feat3_agg2.withColumn(\"rank_qty\", fn.row_number().over(Window.partitionBy(\"client_id\").orderBy(fn.col(\"product_quantity\").desc())))\n",
    "# filter rank \n",
    "df_feat3_agg2_rank = df_feat3_agg2.filter(df_feat3_agg2.rank_qty == 1 )\n",
    "\n",
    "# pivot the redeem flag \n",
    "# product qty \n",
    "\n",
    "df_feat3_agg3 = df_feat3_agg.groupby('client_id','product_id','trans_redeem_flag').agg(fn.sum('product_quantity').alias('product_quantity'))\n",
    "# df_feat3_agg_1 = df_feat3_agg.groupby('client_id').pivot('trans_redeem_flag').agg(fn.first(fn.col('product_id')))\n",
    "\n",
    "# product \n",
    "# df_feat3_agg_2 = df_feat3_agg.groupby('client_id').pivot('trans_redeem_flag').agg(fn.sum('product_quantity').alias('prd_qty'))\n",
    "\n",
    "# # adding row number on purchase and quantity \n",
    "# df_feat3_agg_1 = df_feat3_agg_1.withColumn(\"rank_qty\", fn.row_number().over(Window.partitionBy(\"client_id\").orderBy(fn.col(\"product_quantity\").desc())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200039"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat3_agg2_rank.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o171.showString.\n: org.apache.spark.SparkException: Job 15 cancelled \r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1955)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2205)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2135)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2154)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:472)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3627)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2904)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:300)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:337)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6dcba4f9db3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_feat3_agg2_rank\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\works\\spark_64bit\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    438\u001b[0m         \"\"\"\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\works\\spark_64bit\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1305\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\works\\spark_64bit\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\works\\spark_64bit\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o171.showString.\n: org.apache.spark.SparkException: Job 15 cancelled \r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1955)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2205)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2135)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2154)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:472)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3627)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2904)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:300)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:337)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n"
     ]
    }
   ],
   "source": [
    "df_feat3_agg2_rank.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>trans_redeem_flag</th>\n",
       "      <th>product_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00f6cab0d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.100666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010c5002de</td>\n",
       "      <td>0</td>\n",
       "      <td>1.251880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>018253c9e4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.118742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id  trans_redeem_flag  product_quantity\n",
       "0  00f6cab0d9                  0          1.100666\n",
       "1  010c5002de                  0          1.251880\n",
       "2  018253c9e4                  0          1.118742"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat3_agg.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['client_id', 'trans_redeem_flag', 'product_quantity']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat3_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200039"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat2a.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT client_id)|\n",
      "+-------------------------+\n",
      "|                   200039|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_feat2a.select(fn.countDistinct('client_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_issue_date</th>\n",
       "      <th>first_redeem_date</th>\n",
       "      <th>client_id</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>transaction_datetime</th>\n",
       "      <th>regular_points_received</th>\n",
       "      <th>express_points_received</th>\n",
       "      <th>regular_points_spent</th>\n",
       "      <th>express_points_spent</th>\n",
       "      <th>purchase_sum</th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_quantity</th>\n",
       "      <th>trn_sum_from_iss</th>\n",
       "      <th>trn_sum_from_red</th>\n",
       "      <th>trans_redeem_flag</th>\n",
       "      <th>treatment_flg</th>\n",
       "      <th>target</th>\n",
       "      <th>iss_rdm_diff</th>\n",
       "      <th>trs_rdm_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-14 15:27:21</td>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>00f6cab0d9</td>\n",
       "      <td>ad36e268f7</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>630.59</td>\n",
       "      <td>6f953e34e7</td>\n",
       "      <td>c0f299c302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>-341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-14 15:27:21</td>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>00f6cab0d9</td>\n",
       "      <td>ad36e268f7</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>630.59</td>\n",
       "      <td>6f953e34e7</td>\n",
       "      <td>4009f09b04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>-341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-14 15:27:21</td>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>00f6cab0d9</td>\n",
       "      <td>ad36e268f7</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>630.59</td>\n",
       "      <td>6f953e34e7</td>\n",
       "      <td>439498bce2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>-341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      first_issue_date first_redeem_date   client_id transaction_id  \\\n",
       "0  2017-09-14 15:27:21        2017-12-25  00f6cab0d9     ad36e268f7   \n",
       "1  2017-09-14 15:27:21        2017-12-25  00f6cab0d9     ad36e268f7   \n",
       "2  2017-09-14 15:27:21        2017-12-25  00f6cab0d9     ad36e268f7   \n",
       "\n",
       "  transaction_datetime  regular_points_received  express_points_received  \\\n",
       "0           2018-12-01                      6.3                      0.0   \n",
       "1           2018-12-01                      6.3                      0.0   \n",
       "2           2018-12-01                      6.3                      0.0   \n",
       "\n",
       "   regular_points_spent  express_points_spent  purchase_sum    store_id  \\\n",
       "0                   0.0                   0.0        630.59  6f953e34e7   \n",
       "1                   0.0                   0.0        630.59  6f953e34e7   \n",
       "2                   0.0                   0.0        630.59  6f953e34e7   \n",
       "\n",
       "   product_id  product_quantity  trn_sum_from_iss  trn_sum_from_red  \\\n",
       "0  c0f299c302               1.0              30.0               0.0   \n",
       "1  4009f09b04               1.0               5.0               0.0   \n",
       "2  439498bce2               1.0               0.0               0.0   \n",
       "\n",
       "   trans_redeem_flag  treatment_flg  target  iss_rdm_diff  trs_rdm_diff  \n",
       "0                  0              0       1           102          -341  \n",
       "1                  0              0       1           102          -341  \n",
       "2                  0              0       1           102          -341  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cli_pur.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>treatment_flg</th>\n",
       "      <th>drop_transaction</th>\n",
       "      <th>count(client_id)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  treatment_flg  drop_transaction  count(client_id)\n",
       "0       0              1                 1             15032\n",
       "1       0              0                 0             29165\n",
       "2       1              0                 1             19993\n",
       "3       1              1                 1             21141\n",
       "4       1              0                 0             50675\n",
       "5       1              1                 0             53320\n",
       "6       0              1                 0             26732\n",
       "7       0              0                 1             16658"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cli_pur.groupby('target','treatment_flg','drop_transaction').agg(fn.countDistinct('client_id')).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature aggregation by transaction \n",
    "df_feature = df_cli_pur.groupby('client_id','transaction_id').agg(fn.avg('regular_points_received').alias('regular_points_received'), fn.avg('express_points_spent').alias('express_points_spent') \\\n",
    "                                                                 ,fn.avg('purchase_sum').alias('purchase_sum'),fn.countDistinct('product_id').alias('n_prod')\\\n",
    "                                                                 ,fn.sum('product_quantity').alias('product_quantity'),fn.avg('trn_sum_from_iss').alias('trn_sum_from_iss'),fn.avg('trn_sum_from_red').alias('trn_sum_from_red'))\n",
    "\n",
    "df_feature = df_feature.groupby('client_id').agg(fn.sum('regular_points_received').alias('regular_points_received'),fn.sum('express_points_spent').alias('express_points_spent')\\\n",
    "                                                ,fn.sum('purchase_sum').alias('purchase_sum'),fn.avg('n_prod').alias('avg_n_prod'),fn.sum('product_quantity').alias('avg_n_prod_qty')\\\n",
    "                                                ,fn.sum('trn_sum_from_iss').alias('trn_sum_from_iss'),fn.sum('trn_sum_from_red').alias('trn_sum_from_red'), fn.countDistinct('transaction_id').alias('n_transaction'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top product transactions\n",
    "df_top_product =df_cli_pur.select('client_id','product_id','purchase_sum').groupby('client_id','product_id')\\\n",
    "                .agg(fn.count('product_id').alias('n_product'),fn.sum('purchase_sum').alias('s_purchase'))\n",
    "\n",
    "# adding row number on purchase and quantity \n",
    "df_top_product = df_top_product.withColumn(\"rank_pur\", fn.row_number().over(Window.partitionBy(\"client_id\").orderBy(fn.col(\"s_purchase\").desc())))\n",
    "df_top_product = df_top_product.withColumn(\"rank_qty\", fn.row_number().over(Window.partitionBy(\"client_id\").orderBy(fn.col(\"n_product\").desc())))\n",
    "\n",
    "# filter top product by purchase\n",
    "df_top_product_purchase = df_top_product.filter(df_top_product.rank_pur == 1)\n",
    "\n",
    "# filter top product by quantity\n",
    "df_top_product_qty = df_top_product.filter(df_top_product.rank_qty == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# favorite store \n",
    "df_store_gb = df_cli_pur.select('client_id','transaction_id','store_id','purchase_sum','product_id').groupby('client_id','transaction_id','store_id')\\\n",
    "                    .agg(fn.avg('purchase_sum').alias('s_purchase_sum'), fn.countDistinct('product_id').alias('n_prod_id'))\n",
    "\n",
    "# \n",
    "df_store_gb = df_store_gb.select('client_id','transaction_id','store_id','s_purchase_sum','n_prod_id').groupby('client_id','store_id')\\\n",
    "              .agg(fn.sum('s_purchase_sum').alias('s_purchase_sum'), fn.avg('n_prod_id').alias('avg_n_prod_id'))                  \n",
    "\n",
    "# unique product per store \n",
    "df_store_gb2 = df_cli_pur.select('client_id','store_id','product_id').groupby('client_id','store_id').agg(fn.countDistinct('product_id').alias('n_product'))\n",
    "df_store_gb2 = df_store_gb2.withColumnRenamed('client_id','client_id2').withColumnRenamed('store_id','store_id2')\n",
    "\n",
    "# join with with unique product for each store \n",
    "df_store_gb = df_store_gb.join(df_store_gb2, (df_store_gb.client_id == df_store_gb2.client_id2) & (df_store_gb.store_id == df_store_gb2.store_id2) , 'inner')\n",
    "\n",
    "df_store_gb = df_store_gb.drop('client_id2','store_id2')\n",
    "\n",
    "# put ranking \n",
    "df_store_gb_rank = df_store_gb.withColumn(\"rank_s_purchase\", fn.row_number().over(Window.partitionBy(\"client_id\").orderBy(fn.col(\"s_purchase_sum\").desc())))\n",
    "df_store_gb_rank = df_store_gb_rank.withColumn(\"rank_prod_qty\", fn.row_number().over(Window.partitionBy(\"client_id\").orderBy(fn.col(\"n_product\").desc())))\n",
    "\n",
    "\n",
    "# filter top product by purchase\n",
    "df_store_gb_top_pur = df_store_gb_rank.filter(df_store_gb_rank.rank_s_purchase == 1)\n",
    "\n",
    "# filter top product by quantity\n",
    "df_store_gb_top_qty = df_store_gb_rank.filter(df_store_gb_rank.rank_prod_qty == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join new feature store and products\n",
    "\n",
    "# store purchase \n",
    "df_store_gb_top_pur = df_store_gb_top_pur.withColumnRenamed('client_id','client_id2')\n",
    "df_feature = df_feature.join(df_store_gb_top_pur.select('client_id2','store_id','s_purchase_sum'),df_feature.client_id == df_store_gb_top_pur.client_id2,'left' )\n",
    "df_feature = df_feature.drop('client_id2')\n",
    "df_feature = df_feature.withColumnRenamed('store_id','store_id_pur')\n",
    "\n",
    "# store quantity \n",
    "df_store_gb_top_qty = df_store_gb_top_qty.withColumnRenamed('client_id','client_id2')\n",
    "df_feature = df_feature.join(df_store_gb_top_qty.select('client_id2','store_id','n_product'),df_feature.client_id == df_store_gb_top_qty.client_id2,'left' )\n",
    "df_feature = df_feature.drop('client_id2')\n",
    "df_feature = df_feature.withColumnRenamed('store_id','store_id_pur_qty').withColumnRenamed('n_product','store_n_product')\n",
    "\n",
    "# product purchase \n",
    "df_top_product_purchase = df_top_product_purchase.withColumnRenamed('client_id','client_id2')\n",
    "df_feature = df_feature.join(df_top_product_purchase.select('client_id2','product_id','s_purchase'),df_feature.client_id == df_top_product_purchase.client_id2,'left' )\n",
    "df_feature = df_feature.drop('client_id2')\n",
    "df_feature = df_feature.withColumnRenamed('product_id','product_pur')\n",
    "\n",
    "# product qty \n",
    "df_top_product_qty = df_top_product_qty.withColumnRenamed('client_id','client_id2')\n",
    "df_feature = df_feature.join(df_top_product_qty.select('client_id2','product_id','n_product'),df_feature.client_id == df_top_product_qty.client_id2,'left' )\n",
    "df_feature = df_feature.drop('client_id2')\n",
    "df_feature = df_feature.withColumnRenamed('product_id','product_qty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.repartition(1).write.mode('overwrite').option(\"header\",True).csv(\"D:/works/master_tilburg/dss/thesis/data/feature_stg2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+--------------------+-----------------+------------------+--------------+------------------+----------------+-------------+------------+--------------+----------------+---------------+-----------+----------+-----------+---------+\n",
      "| client_id|regular_points_received|express_points_spent|     purchase_sum|        avg_n_prod|avg_n_prod_qty|  trn_sum_from_iss|trn_sum_from_red|n_transaction|store_id_pur|s_purchase_sum|store_id_pur_qty|store_n_product|product_pur|s_purchase|product_qty|n_product|\n",
      "+----------+-----------------------+--------------------+-----------------+------------------+--------------+------------------+----------------+-------------+------------+--------------+----------------+---------------+-----------+----------+-----------+---------+\n",
      "|02429418df|     37.300000000000004|                 0.0|          4156.77|               8.5|          62.0| 539.9142857142857|             0.0|            6|  d09acf8114|        1349.0|      2fe93e36be|             21| 4009f09b04|    3190.7| 4009f09b04|        3|\n",
      "|02d6c08e7d|     5.8999999999999995|                 0.0|            747.0|1.8888888888888888|          30.0|500.58333333333337|             0.0|            9|  7763d9b151|         721.0|      7763d9b151|              8| 21e8f864ff|     506.0| 21e8f864ff|        7|\n",
      "|03f35da9a5|     30.199999999999996|                 0.0|5661.849999999999|3.6470588235294117|          87.0|            1455.9|             0.0|           17|  04d336aec5|       5661.85|      04d336aec5|             47| 222c727a1d|   2090.06| 222c727a1d|        4|\n",
      "+----------+-----------------------+--------------------+-----------------+------------------+--------------+------------------+----------------+-------------+------------+--------------+----------------+---------------+-----------+----------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_feature.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- regular_points_received: double (nullable = true)\n",
      " |-- express_points_spent: double (nullable = true)\n",
      " |-- purchase_sum: double (nullable = true)\n",
      " |-- avg_n_prod: double (nullable = true)\n",
      " |-- avg_n_prod_qty: double (nullable = true)\n",
      " |-- trn_sum_from_iss: double (nullable = true)\n",
      " |-- trn_sum_from_red: double (nullable = true)\n",
      " |-- n_transaction: long (nullable = false)\n",
      " |-- store_id_pur: string (nullable = true)\n",
      " |-- s_purchase_sum: double (nullable = true)\n",
      " |-- store_id_pur_qty: string (nullable = true)\n",
      " |-- store_n_product: long (nullable = true)\n",
      " |-- product_pur: string (nullable = true)\n",
      " |-- s_purchase: double (nullable = true)\n",
      " |-- product_qty: string (nullable = true)\n",
      " |-- n_product: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_feature.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72824"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+------------------+---------+---------------+-------------+\n",
      "| client_id|  store_id|    s_purchase_sum|     avg_n_prod_id|n_product|rank_s_purchase|rank_prod_qty|\n",
      "+----------+----------+------------------+------------------+---------+---------------+-------------+\n",
      "|02429418df|2fe93e36be|1337.7000000000003|              21.0|       21|              2|            1|\n",
      "|02d6c08e7d|7763d9b151|             721.0|               2.0|        8|              1|            1|\n",
      "|03f35da9a5|04d336aec5|           5661.85|3.6470588235294117|       47|              1|            1|\n",
      "+----------+----------+------------------+------------------+---------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_store_gb_top_qty.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- s_purchase_sum: double (nullable = true)\n",
      " |-- avg_n_prod_id: double (nullable = true)\n",
      " |-- n_product: long (nullable = false)\n",
      " |-- rank_s_purchase: integer (nullable = true)\n",
      " |-- rank_prod_qty: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- s_purchase_sum: double (nullable = true)\n",
      " |-- avg_n_prod_id: double (nullable = true)\n",
      " |-- n_product: long (nullable = false)\n",
      " |-- rank_s_purchase: integer (nullable = true)\n",
      " |-- rank_prod_qty: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_gb_top_pur.printSchema(), df_store_gb_top_qty.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400162, 400162)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_gb_top_qty.count(), df_top_product_qty.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- s_purchase_sum: double (nullable = true)\n",
      " |-- avg_n_prod_id: double (nullable = true)\n",
      " |-- n_product: long (nullable = false)\n",
      " |-- rank_s_purchase: integer (nullable = true)\n",
      " |-- rank_prod_qty: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_store_gb_top_pur.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "|  n|count(client_id)|\n",
      "+---+----------------+\n",
      "|  1|          167362|\n",
      "|  2|           32677|\n",
      "+---+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tes = df_cli_pur.groupby('client_id').agg(fn.countDistinct('drop_transaction').alias('n'))\n",
    "tes.groupby('n').agg(fn.countDistinct('client_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+------+---------------------+----------------+\n",
      "|drop_transaction|treatment_flg|target|count(transaction_id)|count(client_id)|\n",
      "+----------------+-------------+------+---------------------+----------------+\n",
      "|               0|            1|     1|              1321476|           53320|\n",
      "|               0|            0|     0|               361034|           29165|\n",
      "|               1|            0|     1|               253067|           19993|\n",
      "|               1|            1|     1|               260104|           21141|\n",
      "|               1|            0|     0|               118283|           16658|\n",
      "|               1|            1|     0|               107540|           15032|\n",
      "|               0|            1|     0|               329054|           26732|\n",
      "|               0|            0|     1|              1274388|           50675|\n",
      "+----------------+-------------+------+---------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cli_pur.groupby('drop_transaction','treatment_flg','target').agg(fn.countDistinct('transaction_id'),fn.countDistinct('client_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232716"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "53320 + 29165 + 19993 + 21141 + 16658 + 15032 + 26732 + 50675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------------+----------------+\n",
      "|drop_transaction|count(transaction_id)|count(client_id)|\n",
      "+----------------+---------------------+----------------+\n",
      "|               1|              1479837|          145869|\n",
      "|               0|              6565370|          319733|\n",
      "+----------------+---------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cli_pur.groupby('drop_transaction').agg(fn.countDistinct('transaction_id'),fn.countDistinct('client_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+---+------+-----------------+\n",
      "| client_id|   first_issue_date|age|gender|first_redeem_date|\n",
      "+----------+-------------------+---+------+-----------------+\n",
      "|000048b7a6|2018-12-15 13:33:11| 68|     F|       2019-11-20|\n",
      "+----------+-------------------+---+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cli.filter(df_cli.client_id == '000048b7a6' ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+---+------+-------------------+\n",
      "| client_id|   first_issue_date|age|gender|  first_redeem_date|\n",
      "+----------+-------------------+---+------+-------------------+\n",
      "|000012768d|2017-08-05 15:40:48| 45|     U|2018-01-04 19:30:07|\n",
      "|000036f903|2017-04-10 13:54:23| 72|     F|2017-04-23 12:37:56|\n",
      "|000048b7a6|2018-12-15 13:33:11| 68|     F|         2019-11-20|\n",
      "+----------+-------------------+---+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cli.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----------------+---+------+------------------+\n",
      "|client_id|first_issue_date|first_redeem_date|age|gender|first_redeem_date2|\n",
      "+---------+----------------+-----------------+---+------+------------------+\n",
      "|        0|               0|            35469|  0|     0|                 0|\n",
      "+---------+----------------+-----------------+---+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cli.select([fn.count(fn.when(fn.isnan(c) | fn.col(c).isNull(), c)).alias(c) for c in df_cli.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------------------+\n",
      "|min(first_redeem_date)|max(first_redeem_date)|\n",
      "+----------------------+----------------------+\n",
      "|   2017-04-11 09:42:20|   2019-11-20 12:37:56|\n",
      "+----------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cli.select(fn.min('first_redeem_date'),fn.max('first_redeem_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- first_issue_date: string (nullable = true)\n",
      " |-- first_redeem_date: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cli.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- transaction_datetime: string (nullable = true)\n",
      " |-- regular_points_received: double (nullable = true)\n",
      " |-- express_points_received: double (nullable = true)\n",
      " |-- regular_points_spent: double (nullable = true)\n",
      " |-- express_points_spent: double (nullable = true)\n",
      " |-- purchase_sum: double (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_quantity: double (nullable = true)\n",
      " |-- trn_sum_from_iss: double (nullable = true)\n",
      " |-- trn_sum_from_red: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pur.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
